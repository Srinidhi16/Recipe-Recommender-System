{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "57bc199a",
   "metadata": {},
   "source": [
    "# Cheesecake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "a2bce73e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "import json\n",
    "from spacy.tokens import DocBin\n",
    "import spacy\n",
    "from tqdm import tqdm\n",
    "from spacy.tokens import DocBin\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "a9c60eb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\Admin\\\\Documents\\\\Praxis\\\\Term 3\\\\CAPP\\\\NER\\\\NER_train\\\\cheesecake'"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "86c2eda7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(file):\n",
    "    with open (file, \"r\", encoding=\"utf-8\") as f:\n",
    "        data = json.load(f)\n",
    "    return (data)\n",
    "\n",
    "def write_data(file, data):\n",
    "    with open (file, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(data, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "a1c82d77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# new entity label\n",
    "LABEL = 'INGREDIENT'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d50d4fb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = load_data(r\"./cheesecake_json.json\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "bb8ea537",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = int(len())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "50bfbea7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "89"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "b4cfa177",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = load_data(r\"./cheesecake_json.json\")\n",
    "def convert_data(data):\n",
    "    final = []\n",
    "    for item in data:\n",
    "        text = item[\"text\"]\n",
    "        ents = item[\"spans\"]\n",
    "        final_ents = []\n",
    "        for ent in ents:\n",
    "            start, end, label = ent[\"start\"], ent[\"end\"], ent[\"label\"]\n",
    "            final_ents.append([start, end, label])\n",
    "        ents = {\"entities\": final_ents}\n",
    "        final.append([text, ents])\n",
    "    return (final)\n",
    "df = convert_data(df)\n",
    "random.shuffle(df)\n",
    "ch_train = df[0:65]\n",
    "ch_valid = df[65:]\n",
    "write_data(r\"./cheesecake_json.json\", ch_train)\n",
    "write_data(r\"./cheesecake_json.json\", ch_valid)\n",
    "#print (ch_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "99b0ab1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.blank(\"en\") \n",
    "def create_training(TRAIN_DATA):\n",
    "    db = DocBin() # create a DocBin object\n",
    "    for text, annot in tqdm(TRAIN_DATA): # data in previous format\n",
    "        doc = nlp.make_doc(text) # create doc object from text\n",
    "        ents = []\n",
    "        for start, end, label in annot[\"entities\"]: # add character indexes\n",
    "            span = doc.char_span(start, end, label=label, alignment_mode=\"contract\")\n",
    "            if span is None:\n",
    "                print(\"Skipping entity\")\n",
    "            else:\n",
    "                ents.append(span)\n",
    "        doc.ents = ents # label the text with the ents\n",
    "        db.add(doc)\n",
    "    return (db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "1b015d79",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 65/65 [00:00<00:00, 1140.34it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 24/24 [00:00<00:00, 1599.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping entity\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "ch_train = create_training(ch_train)\n",
    "ch_train.to_disk(\"./ch_train.spacy\")\n",
    "\n",
    "ch_valid = create_training(ch_valid)\n",
    "ch_valid.to_disk(\"./ch_valid.spacy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "98a58ee6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[+] Auto-filled config with all values\n",
      "[+] Saved config\n",
      "config.cfg\n",
      "You can now add your data and train your pipeline:\n",
      "python -m spacy train config.cfg --paths.train ./train.spacy --paths.dev ./dev.spacy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-28 20:39:12.469060: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'cudart64_110.dll'; dlerror: cudart64_110.dll not found\n",
      "2022-04-28 20:39:12.469119: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy init fill-config ./base_config.cfg ./config.cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "9ee057f7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[+] Created output directory: output\n",
      "[i] Saving to output directory: output\n",
      "[i] Using CPU\n",
      "\u001b[1m\n",
      "=========================== Initializing pipeline ===========================\u001b[0m\n",
      "[+] Initialized pipeline\n",
      "\u001b[1m\n",
      "============================= Training pipeline =============================\u001b[0m\n",
      "[i] Pipeline: ['tok2vec', 'ner']\n",
      "[i] Initial learn rate: 0.001\n",
      "E    #       LOSS TOK2VEC  LOSS NER  ENTS_F  ENTS_P  ENTS_R  SCORE \n",
      "---  ------  ------------  --------  ------  ------  ------  ------\n",
      "  0       0          0.00     64.00    0.00    0.00    0.00    0.00\n",
      " 64     200         46.85   1123.24   89.80   88.00   91.67    0.90\n",
      "132     400          0.00      0.00   89.80   88.00   91.67    0.90\n",
      "231     600          0.00      0.00   89.80   88.00   91.67    0.90\n",
      "331     800          0.00      0.00   89.80   88.00   91.67    0.90\n",
      "436    1000          0.00      0.00   89.80   88.00   91.67    0.90\n",
      "636    1200          0.00      0.00   89.80   88.00   91.67    0.90\n",
      "836    1400          0.00      0.00   89.80   88.00   91.67    0.90\n",
      "1036    1600          0.00      0.00   89.80   88.00   91.67    0.90\n",
      "1236    1800          0.00      0.00   89.80   88.00   91.67    0.90\n",
      "[+] Saved pipeline to output directory\n",
      "output\\model-last\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-28 20:41:40.730542: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'cudart64_110.dll'; dlerror: cudart64_110.dll not found\n",
      "2022-04-28 20:41:40.730597: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "[2022-04-28 20:41:45,382] [INFO] Set up nlp object from config\n",
      "[2022-04-28 20:41:45,399] [INFO] Pipeline: ['tok2vec', 'ner']\n",
      "[2022-04-28 20:41:45,403] [INFO] Created vocabulary\n",
      "[2022-04-28 20:41:45,406] [INFO] Finished initializing nlp object\n",
      "[2022-04-28 20:41:45,609] [INFO] Initialized pipeline components: ['tok2vec', 'ner']\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy train config.cfg --output ./output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "9102b4b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = load_data(\"./test_data.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "10fb2531",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "f442aead",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': '125g butter melted', 'spans': [{'start': 5, 'end': 11, 'label': 'INGREDIENT'}]}\n"
     ]
    }
   ],
   "source": [
    "print(test_data[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "20790ee9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'125g butter melted'"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data[1]['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "ba33ff67",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"output/model-best\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "f2e45bd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(test_data[1]['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "748a9963",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "packet INGREDIENT\n",
      "biscuits INGREDIENT\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(test_data[0]['text'])\n",
    "for ent in doc.ents:\n",
    "    print(ent.text,ent.label_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "270a53b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_data:0\n",
      "packet INGREDIENT 5 11\n",
      "biscuits INGREDIENT 24 32\n",
      "test_data:1\n",
      "butter INGREDIENT 5 11\n",
      "test_data:2\n",
      "cream cheese INGREDIENT 17 29\n",
      "test_data:3\n",
      "caster sugar INGREDIENT 8 20\n",
      "test_data:4\n",
      "cream INGREDIENT 13 18\n",
      "test_data:5\n",
      "vanilla extract INGREDIENT 6 21\n",
      "test_data:6\n",
      "finely INGREDIENT 6 12\n",
      "lemon INGREDIENT 20 25\n",
      "test_data:7\n",
      "raspberries INGREDIENT 7 18\n",
      "test_data:8\n",
      "digestive INGREDIENT 10 19\n",
      "test_data:9\n",
      "butter INGREDIENT 20 26\n",
      "test_data:10\n",
      "sugar INGREDIENT 18 23\n",
      "test_data:11\n",
      "cream INGREDIENT 13 18\n",
      "test_data:12\n",
      "starch INGREDIENT 18 24\n",
      "test_data:13\n",
      "sugar INGREDIENT 28 33\n",
      "test_data:14\n",
      "cream cheese INGREDIENT 7 19\n",
      "test_data:15\n",
      "egg INGREDIENT 2 5\n",
      "test_data:16\n",
      "vanilla extract INGREDIENT 11 26\n",
      "test_data:17\n",
      "lemon INGREDIENT 13 18\n",
      "test_data:18\n",
      "graham cracker INGREDIENT 7 21\n",
      "test_data:19\n",
      "butter INGREDIENT 4 10\n",
      "test_data:20\n",
      "sugar INGREDIENT 10 15\n",
      "test_data:21\n",
      "cream cheese INGREDIENT 19 31\n",
      "test_data:22\n",
      "eggs INGREDIENT 2 6\n",
      "test_data:23\n",
      "vanilla extract INGREDIENT 13 28\n",
      "test_data:24\n",
      "sugar INGREDIENT 12 17\n",
      "test_data:25\n",
      "cream INGREDIENT 11 16\n",
      "test_data:26\n",
      "cream INGREDIENT 12 17\n",
      "test_data:27\n",
      "sugar INGREDIENT 10 15\n"
     ]
    }
   ],
   "source": [
    "j = 0\n",
    "for i in test_data:\n",
    "    print(\"test_data:\"+ str(j))\n",
    "    doc= nlp(i['text'])\n",
    "    for ent in doc.ents:\n",
    "        print(ent.text,ent.label_,ent.start_char,ent.end_char)\n",
    "    j += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c557637e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
